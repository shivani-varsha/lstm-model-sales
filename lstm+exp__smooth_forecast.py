# -*- coding: utf-8 -*-
"""LSTM+exp_ smooth forecast.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mFhqYXuRpIPleyZPup--XF53YWTRH4Zd
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Load the data from CSV file
data = pd.read_csv("/content/drive/MyDrive/data_modified.csv")
data1= pd.read_csv("/content/drive/MyDrive/data01.csv")

from google.colab import drive
drive.mount('/content/drive')

data1.columns

data = pd.concat([data, data1['Date']], axis=1)

data.head()

data['Date'] = pd.to_datetime(data['Date'])

data.set_index('Date', inplace=True)
data.sort_values(by='Date', ascending=True,inplace=True)

from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import r2_score

data

data.to_csv('/content/final_data.csv', index=False)

!pip install tensorflow scikit-learn

!pip install --upgrade tensorflow

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# Load your time series data (replace with your own dataset)
# Assume you have a DataFrame 'data' with a column named 'Quantity' (or any other relevant column)

# Apply exponential smoothing
alpha = 0.2 # Smoothing parameter (adjust as needed)
data['Smoothed_Quantity'] = data['Quantity'].ewm(alpha=alpha, adjust=False).mean()

# Plotting the results
plt.figure(figsize=(12, 6))
plt.plot(data.index, data['Quantity'], label='Original Quantity', color='blue')
plt.plot(data.index, data['Smoothed_Quantity'], label='Smoothed Quantity', linestyle='solid', color='red')
plt.legend()
plt.xlabel('Time')
plt.ylabel('Value')
plt.title('Exponential Smoothing of Quantity')
plt.show()

data.head()

data= data.drop(['Crude_oil_Price'	,'Gold_Price',	'S&P_500_Price'	,'Nasdaq_100_Price', 'Crude_oil_Price_lag1',	'Gold_Price_lag1',	'S&P_500_Price_lag1','Nasdaq_100_Price_lag1',	'Crude_oil_Price_mean_rolling',	'Gold_Price_mean_rolling',	'S&P_500_Price_mean_rolling',	'Nasdaq_100_Price_mean_rolling'],axis=1)

data= data.drop(['Quantity'],axis=1)

# Define the split ratio
train_ratio = 0.8
test_ratio = 0.2

# Calculate the number of samples in each split
train_size = int(len(data) * train_ratio)
test_size = len(data) - train_size

# Shuffle the dataset
data = data.sample(frac=1).reset_index(drop=True)

# Split the dataset
train_df = data.iloc[:train_size]
test_df = data.iloc[train_size:]

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from tensorflow.keras.optimizers import Adam
# Load your multivariate time series data (replace with your own dataset)
# Assume you have a DataFrame 'data' with columns: 'Smoothed_Quantity'
custom_lr = 0.003# Set your desired learning rate
optimizer = Adam(learning_rate=custom_lr)
# Normalize the data
scaler = MinMaxScaler(feature_range=(-1, 1))
data_scaled = scaler.fit_transform(train_df[['Smoothed_Quantity']])

# Create input sequences and target values
window_size = 5
X, y = [], []
for i in range(len(train_df) - window_size):
    X.append(data_scaled[i:i + window_size])
    y.append(data_scaled[i + window_size])

X_train, y_train = np.array(X), np.array(y)

# Build the LSTM model
model = Sequential([
    LSTM(units=64, input_shape=(window_size, 1), activation='relu', return_sequences=True),
    LSTM(units=32, activation='relu'),
    Dense(1)
])
model.compile(loss='mean_squared_error', optimizer=optimizer)

# Train the model
model.fit(X_train, y_train, epochs=280, batch_size=10, verbose=2, validation_split=0.35)

# Make predictions
train_predictions = model.predict(X_train)

# Inverse transform predictions to original scale
train_predictions_original = scaler.inverse_transform(train_predictions)

# Plotting the results
plt.figure(figsize=(12, 6))
plt.plot(train_df.index[window_size:], train_df['Smoothed_Quantity'][window_size:], label='True Quantity')
plt.plot(train_df.index[window_size:], train_predictions_original[:, 0], label='Predicted Quantity', linestyle='solid', color='red')
plt.legend()
plt.xlabel('Time')
plt.ylabel('Quantity')
plt.title('Quantity Forecasting using LSTM')
plt.show()

from sklearn.metrics import mean_squared_error
#train accuracy
mse = mean_squared_error(y_train, train_predictions_original)
print(f"MSE: {mse:.4f}")
rmse = np.sqrt(mse)
print(f"RMSE: {rmse:.4f}")
from sklearn.metrics import mean_absolute_error

# Assuming you have 'y_test' and 'y_pred_test_original'
mae = mean_absolute_error(y_train, train_predictions_original)
print(f"MAE: {mae:.4f}")

# Prepare the test data for predictions
test_scaled = scaler.fit_transform(test_df[['Smoothed_Quantity']])
X_test, y_test = [], []
for i in range(len(test_df) - window_size):
    X_test.append(test_scaled[i:i + window_size])
    y_test.append(test_scaled[i + window_size])

X_test, y_test = np.array(X_test), np.array(y_test)
# Make predictions on the test data
test_predictions = model.predict(X_test)

# Inverse transform test predictions to original scale
test_predictions_original = scaler.inverse_transform(test_predictions)

# Plotting the test results
plt.figure(figsize=(12, 6))
plt.plot(test_df.index[window_size:], test_df['Smoothed_Quantity'][window_size:], label='True Quantity')
plt.plot(test_df.index[window_size:], test_predictions_original[:, 0], label='Predicted Quantity', linestyle='solid', color='red')
plt.legend()
plt.xlabel('Time')
plt.ylabel('Quantity')
plt.title('Quantity Forecasting using LSTM (Test)')
plt.show()

from sklearn.metrics import mean_squared_error
#test accuracy
mse = mean_squared_error(y_test,test_predictions_original)
print(f"MSE: {mse:.4f}")
rmse = np.sqrt(mse)
print(f"RMSE: {rmse:.4f}")
from sklearn.metrics import mean_absolute_error

# Assuming you have 'y_test' and 'y_pred_test_original'
mae = mean_absolute_error(y_test,test_predictions_original
)
print(f"MAE: {mae:.4f}")